

model_name: meta-llama/Llama-3.2-3B-Instruct
sentence_transformer_model: BAAI/bge-m3
experiment_name: hard-prompting-context-label-10-hop-1
checkpoint_path: models
graph_path: data/gnd.pickle
dataset_path: datasets/labelwise-10-hop-1
num_epochs: 1
batch_size: 32
learning_rate: 5e-5
warmup_rate: 0.05
max_grad_norm: 1.0
max_seq_length: 200
max_context_length: 200
eval_steps: 200
logging_steps: 10
save_steps: 2000
eval_generation: true
train_subsample_ratio: 1.0
validate_subsample_ratio: 0.03
sort_by_freq: true
use_k_freq_labels: 0 # Use 0 to disable k-freq labels, or set to a positive integer

context:
  context_type: text # Choices: "text" or "graph". Use null if no context is needed.
  top_k: 10 # How many instances to retrieve
  hops: 1 # Also include hops in the knowledge graph from retrieved instances
  title_wise: false # Whether to retrieve title-to-label or title-to-title
  relation: null # Choices: null (use all relations) "broader" or "related"
  index_path: "data/label_index.pkl"
  mapping_path: "data/label_mapping.pkl"
