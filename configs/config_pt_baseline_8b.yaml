model_name: meta-llama/Llama-3.1-8B
sentence_transformer_model: BAAI/bge-m3
experiment_name: prompt-tuning-baseline-8b

context:
  context_type: null # Choices: "text" or "graph". Use null if no context is needed.
  top_k: 0 # How many instances to retrieve
  hops: 0 # Also include hops in the knowledge graph from retrieved instances
  title_wise: false # Whether to retrieve title-to-label or title-to-title
  relation: null # Choices: null (use all relations) "broader" or "related"
  index_path: "search_indices/label_index.pkl"
  mapping_path: "search_indices/label_mapping.pkl"

prompt_config:
  num_prompt_tokens: 100
  at_layer: 30
  hidden_size: 4096
  down_project_size: 3072
  dropout: 0.1
  type: "hidden_states" # Choices: "hidden_states", "random" or "context"