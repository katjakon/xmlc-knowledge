model_name: meta-llama/Llama-3.2-3B
experiment_name: prompt-tuning-gnd-only-names
eval_generation: false

context:
  context_type: "text" # Choices: "text" or "graph". Use null if no context is needed.

prompt_config:
  num_prompt_tokens: 50
  at_layer: 25
  hidden_size: 3072
  down_project_size: 1024
  dropout: 0.1
  type: "hidden_states" # Choices: "hidden_states", "random" or "context"