{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "from statistics import mean\n",
    "from datasets import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from safetensors import safe_open\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import logging\n",
    "\n",
    "from yaml import safe_load\n",
    "\n",
    "from prompt_str import SUFFIX_PROMPT, PREFIX_PROMPT\n",
    "from retriever import Retriever\n",
    "from reranker import BGEReranker\n",
    "from utils import init_prompt_model, get_label_mapping, recall_at_k, precision_at_k, f1_at_k, get_pref_label, inference_tokenize, load_model\n",
    "\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"config.yaml\"\n",
    "checkpoint_path = \"hyperparams/best_model/model.safetensors\"\n",
    "test_data = \"data/title_test.feather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_feather(test_data)\n",
    "config = safe_load(open(config_path, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5275584db4ff49539e1cfc4e12ca52f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = load_model(checkpoint_path, config=config, device=DEVICE, data_parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e464a803384f1fb012eb62a9f9fcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8414 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ds = Dataset.from_pandas(test_df)\n",
    "test_ds = test_ds.map(\n",
    "    lambda x: inference_tokenize(x, tokenizer, max_length=75, suffix=SUFFIX_PROMPT, prefix=PREFIX_PROMPT),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8414 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8414/8414 [1:12:58<00:00,  1.92it/s]\n"
     ]
    }
   ],
   "source": [
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "#model.pad_token_id = tokenizer.pad_token_id\n",
    "predictions = []\n",
    "for title_batch in tqdm(test_ds):\n",
    "    input_ids = torch.tensor(title_batch[\"input_ids\"]).to(DEVICE).unsqueeze(0)\n",
    "    attention_mask = torch.tensor(title_batch[\"attention_mask\"]).to(DEVICE).unsqueeze(0)\n",
    "    seq_lengths = torch.tensor(title_batch[\"seq_lengths\"]).to(DEVICE).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        out = model.module.generate(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            seq_lengths=seq_lengths)\n",
    "    len_input = len(input_ids[0])\n",
    "    out = out[0][len_input:]  # Remove the input part of the output\n",
    "    out_str = tokenizer.decode(out, skip_special_tokens=True)\n",
    "    out_str = [x.strip() for x in out_str.split(\";\") if x != \"\"]\n",
    "    #out_str = process_output(out_str)\n",
    "    predictions.append(list(out_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Die Landesministerkonferenzen und der Bund kooperativer Föderalismus im Schatten der Politikverflechtung\n",
      "Predictions: ['Deutschland', 'Länder', 'Kooperatives Föderalismusmodell']\n",
      "------------------------------------------------------------------------------------------\n",
      "Title: Die Geburt der Philosophie im Garten der Lüste Michel Foucaults Archäologie des platonischen Eros\n",
      "Predictions: ['Philosophie', 'Plato', 'Foucault, Michel (-)']\n",
      "------------------------------------------------------------------------------------------\n",
      "Title: Das Geldwäscherisiko verschiedener Glücksspielarten\n",
      "Predictions: ['Glücksspiel', 'Glücksspielrisiko']\n",
      "------------------------------------------------------------------------------------------\n",
      "Title: Entwicklung von großvolumigen CdTe- und (Cd,Zn)Te-Detektorsystemen\n",
      "Predictions: ['ZnTe', 'Schichtwechsel', 'Halbleiter', 'Dosismessung', 'Cadmium']\n",
      "------------------------------------------------------------------------------------------\n",
      "Title: Integrierte bioinformatische Methoden zur reproduzierbaren und transparenten Hochdurchsatz-Analyse von Life Science Big Data\n",
      "Predictions: ['Bioinformatik', 'Hochdurchsatzanalyse', 'Genomanalyse', 'Proteom']\n",
      "------------------------------------------------------------------------------------------\n",
      "Title: Untersuchung der Barriereschädigung des choroidalen Plexusepithels durch Streptococcus suis und deren pharmakologischen Beeinflussbarkeit\n",
      "Predictions: ['Tiermodell', 'Streptococcus suis', 'Choroidales Plexus']\n",
      "------------------------------------------------------------------------------------------\n",
      "Title: iOS-Apps programmieren mit Swift Der leichte Einstieg in die Entwicklung für iPhone, iPad und Co. – inkl. Apple Watch und Apple TV\n",
      "Predictions: ['Swift (Programmiersprache)']\n",
      "------------------------------------------------------------------------------------------\n",
      "Title: Kunstverdacht Art-suspect\n",
      "Predictions: ['Kunst', 'Kunstmarkt']\n",
      "------------------------------------------------------------------------------------------\n",
      "Title: Pattern Matching auf FPGAs\n",
      "Predictions: ['FPGA', 'Mustererkennung']\n",
      "------------------------------------------------------------------------------------------\n",
      "Title: Partizipative Planungsinstrumente für eine nachhaltige multifunktionale Waldbewirtschaftung vergleichende Anwendung und Nutzerevaluation des Analytisch Hierarchischen Prozesses und der Nutzwertanalyse\n",
      "Predictions: ['Nachhaltigkeit', 'Waldbewirtschaftung', 'Nutzwertanalyse', 'Partizipation']\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_pred = len(predictions[:10])\n",
    "for pred, title in zip(predictions, test_ds[\"title\"][:n_pred]):\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Predictions: {pred}\")\n",
    "    print(\"---\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"predictions\"] = predictions    \n",
    "test_df.to_feather(\"data/title_best_predictions.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_predictions(pred_list):\n",
    "    pred_list = [x for x in pred_list if len(x) > 0]\n",
    "    return list(set(pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"predictions\"] = test_df[\"predictions\"].apply(filter_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>predictions</th>\n",
       "      <th>label_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>Alles Schicksal? Wie wir uns aus Familienmuste...</td>\n",
       "      <td>[Sozialpsychologie, Familie, Soz, Identitätsfi...</td>\n",
       "      <td>[Prägung, Familienbeziehung, Identitätsentwick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8090</th>\n",
       "      <td>Vom Domänenamt Schöneck zur Domäne Pogutken...</td>\n",
       "      <td>[Schönken (Ostpreußen, Pogutken (Ostpreußen)]</td>\n",
       "      <td>[Domänenamt, Skarszewy, Generalpächter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>In der Erinnerung ankern Die Trauer von Kinder...</td>\n",
       "      <td>[Kind, Trauerarbeit, Memory-Book, Jugend]</td>\n",
       "      <td>[Jugend, Kind, Begleitung (Psychologie), Traue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7546</th>\n",
       "      <td>Lösungen zum Lehrbuch Corporate Finance Theor...</td>\n",
       "      <td>[Corporate Finance]</td>\n",
       "      <td>[Finanzmanagement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6922</th>\n",
       "      <td>Damit aus meiner Trauer Liebe wird Neue Wege i...</td>\n",
       "      <td>[Trauerarbeit]</td>\n",
       "      <td>[Trauerarbeit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>„Beruf und Berufung“ Die evangelische Geistlic...</td>\n",
       "      <td>[Evangelische Kirche, Geistliche, Geistliches ...</td>\n",
       "      <td>[Evangelische Kirche, Pommern, Konfessionalisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8232</th>\n",
       "      <td>75 Coachingkarten Achtsamkeits- und Weisheitsg...</td>\n",
       "      <td>[Coaching]</td>\n",
       "      <td>[Erzählung, Coaching]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5580</th>\n",
       "      <td>Bondifaktoren Ein natürlicher Zugang zur spez...</td>\n",
       "      <td>[Bondifaktor, Relativitätstheorie]</td>\n",
       "      <td>[Spezielle Relativitätstheorie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>Roloff/Matek Maschinenelemente Aufgabensammlun...</td>\n",
       "      <td>[Maschinenelement]</td>\n",
       "      <td>[Maschinenelement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>Der Unmittelbarkeitsgrundsatz im Zivilprozess ...</td>\n",
       "      <td>[Unmittelbarkeit, Zivilprozess, Deutschland]</td>\n",
       "      <td>[Deutschland, Zivilprozess, Unmittelbarkeitsgr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "6054  Alles Schicksal? Wie wir uns aus Familienmuste...   \n",
       "8090  Vom Domänenamt Schöneck zur Domäne Pogutken...   \n",
       "65    In der Erinnerung ankern Die Trauer von Kinder...   \n",
       "7546  Lösungen zum Lehrbuch Corporate Finance Theor...   \n",
       "6922  Damit aus meiner Trauer Liebe wird Neue Wege i...   \n",
       "1457  „Beruf und Berufung“ Die evangelische Geistlic...   \n",
       "8232  75 Coachingkarten Achtsamkeits- und Weisheitsg...   \n",
       "5580  Bondifaktoren Ein natürlicher Zugang zur spez...   \n",
       "6991  Roloff/Matek Maschinenelemente Aufgabensammlun...   \n",
       "1672  Der Unmittelbarkeitsgrundsatz im Zivilprozess ...   \n",
       "\n",
       "                                            predictions  \\\n",
       "6054  [Sozialpsychologie, Familie, Soz, Identitätsfi...   \n",
       "8090      [Schönken (Ostpreußen, Pogutken (Ostpreußen)]   \n",
       "65            [Kind, Trauerarbeit, Memory-Book, Jugend]   \n",
       "7546                                [Corporate Finance]   \n",
       "6922                                     [Trauerarbeit]   \n",
       "1457  [Evangelische Kirche, Geistliche, Geistliches ...   \n",
       "8232                                         [Coaching]   \n",
       "5580                 [Bondifaktor, Relativitätstheorie]   \n",
       "6991                                 [Maschinenelement]   \n",
       "1672       [Unmittelbarkeit, Zivilprozess, Deutschland]   \n",
       "\n",
       "                                             label_list  \n",
       "6054  [Prägung, Familienbeziehung, Identitätsentwick...  \n",
       "8090            [Domänenamt, Skarszewy, Generalpächter]  \n",
       "65    [Jugend, Kind, Begleitung (Psychologie), Traue...  \n",
       "7546                                 [Finanzmanagement]  \n",
       "6922                                     [Trauerarbeit]  \n",
       "1457  [Evangelische Kirche, Pommern, Konfessionalisi...  \n",
       "8232                              [Erzählung, Coaching]  \n",
       "5580                    [Spezielle Relativitätstheorie]  \n",
       "6991                                 [Maschinenelement]  \n",
       "1672  [Deutschland, Zivilprozess, Unmittelbarkeitsgr...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(10)[[\"title\", \"predictions\", \"label_list\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd_path = \"data/gnd.pickle\"\n",
    "gnd = pickle.load(open(gnd_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_model_str = 'BAAI/bge-m3'\n",
    "retriever = Retriever(retriever_model_str, device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_strings, label_mapping = get_label_mapping(gnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe42cab3c2b42889f7ab5c287167603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/677 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = retriever.fit(labels=label_strings, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8414/8414 [06:03<00:00, 23.16it/s]\n"
     ]
    }
   ],
   "source": [
    "mapped_labels = []\n",
    "for row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    pred_list = row[1][\"predictions\"]\n",
    "    current_mapping = []\n",
    "    for pred in pred_list:\n",
    "        distance, idns = retriever.retrieve(\n",
    "            mapping=label_mapping,\n",
    "            labels=label_strings,\n",
    "            index=index,\n",
    "            texts=[pred],\n",
    "            top_k=1)\n",
    "        idn_sim = zip(idns[0], distance[0])\n",
    "        current_mapping.extend(idn_sim)\n",
    "    current_mapping = sorted(current_mapping, key=lambda x: x[1])\n",
    "    current_mapping = [x[0] for x in current_mapping]\n",
    "    current_mapping = list(set(current_mapping))\n",
    "    mapped_labels.append(current_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"pred_idns\"] = mapped_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.33643151410562866\n",
      "Precision: 0.19229855003565488\n",
      "F1: 0.22324013955450137\n"
     ]
    }
   ],
   "source": [
    "rec_all = []\n",
    "prec_all = []\n",
    "f1_all = []\n",
    "k = 5\n",
    "for preds_i, golds_i in test_df[[\"pred_idns\", \"label-idn\"]].itertuples(index=False):\n",
    "    rec_all.append(recall_at_k(y_pred=preds_i, y_true=golds_i, k=k))\n",
    "    prec_all.append(precision_at_k(y_pred=preds_i, y_true=golds_i, k=k))\n",
    "    f1_all.append(f1_at_k(y_pred=preds_i, y_true=golds_i, k=k))\n",
    "print(f\"Recall: {mean(rec_all)}\\nPrecision: {mean(prec_all)}\\nF1: {mean(f1_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_str = 'BAAI/bge-reranker-v2-m3'\n",
    "reranker = BGEReranker(reranker_str, device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8414/8414 [00:00<00:00, 108120.56it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pair_dict = {\n",
    "    \"pair\": [],\n",
    "    \"label-idn\": [],\n",
    "    \"title-idx\": []\n",
    "}\n",
    "\n",
    "c = 0\n",
    "for idx, (row) in tqdm(enumerate(test_df.itertuples()), total=len(test_df)):\n",
    "    idn_i_list = row.pred_idns\n",
    "    title_i = row.title\n",
    "    for idn_i in idn_i_list:\n",
    "        idn_i_str = get_pref_label(gnd, idn_i)\n",
    "        pair_dict[\"pair\"].append((title_i, idn_i_str))\n",
    "        pair_dict[\"label-idn\"].append(idn_i)\n",
    "        pair_dict[\"title-idx\"].append(idx)\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example):\n",
    "    pair = example[\"pair\"]\n",
    "    return reranker.tokenizer(pair, padding=True, truncation=True, return_tensors='pt', max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e87e665c90348519d63abe78981c3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = Dataset.from_dict(pair_dict)\n",
    "ds = ds.map(tokenize, batched=True, batch_size=2000)\n",
    "ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label-idn', 'title-idx'])\n",
    "dataloader = DataLoader(ds, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228/228 [00:55<00:00,  4.09it/s]\n"
     ]
    }
   ],
   "source": [
    "sim = {\n",
    "    \"title-idx\": [],\n",
    "    \"label-idn\": [],\n",
    "    \"score\": []\n",
    "}\n",
    "reranker.model.to(DEVICE)\n",
    "for batch in tqdm(dataloader):\n",
    "    scores = reranker.similarities(\n",
    "        batch[\"input_ids\"].to(DEVICE),\n",
    "        batch[\"attention_mask\"].to(DEVICE)\n",
    "    )\n",
    "    sim[\"title-idx\"].extend(batch[\"title-idx\"])\n",
    "    sim[\"label-idn\"].extend(batch[\"label-idn\"])\n",
    "    sim[\"score\"].extend(scores.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim = pd.DataFrame(sim)\n",
    "df_sim[\"title-idx\"] = df_sim[\"title-idx\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8414/8414 [00:03<00:00, 2431.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.21862605311915984\n",
      "Precision@1: 0.5177085809365344\n",
      "F1@1: 0.2804121353384486\n",
      "-----------------\n",
      "Recall@2: 0.29315750178300687\n",
      "Precision@2: 0.3876277632517233\n",
      "F1@2: 0.3021702355431854\n",
      "-----------------\n",
      "Recall@3: 0.32199141118501706\n",
      "Precision@3: 0.2975596228508042\n",
      "F1@3: 0.2799625741604447\n",
      "-----------------\n",
      "Recall@5: 0.33643151410562866\n",
      "Precision@5: 0.19229855003565488\n",
      "F1@5: 0.22324013955450137\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recall_dict = {}\n",
    "precision_dict = {}\n",
    "f1_dict = {}\n",
    "ks = [1, 2,  3, 5]\n",
    "\n",
    "for idx in tqdm(set(df_sim[\"title-idx\"])):\n",
    "    df_i = df_sim[df_sim[\"title-idx\"] == idx]\n",
    "    df_i = df_i.sort_values(by=\"score\", ascending=False)\n",
    "    pred = df_i[\"label-idn\"].tolist()\n",
    "    gold = test_df[\"label-idn\"].iloc[idx]\n",
    "    for k in ks:\n",
    "        if k not in recall_dict:\n",
    "            recall_dict[k] = []\n",
    "            precision_dict[k] = []\n",
    "            f1_dict[k] = []\n",
    "        recall_dict[k].append(recall_at_k(y_pred=pred, y_true=gold, k=k))\n",
    "        precision_dict[k].append(precision_at_k(y_pred=pred, y_true=gold, k=k))\n",
    "        f1_dict[k].append(f1_at_k(y_pred=pred, y_true=gold, k=k))\n",
    "\n",
    "for k in ks:\n",
    "    print(f\"Recall@{k}: {mean(recall_dict[k])}\")\n",
    "    print(f\"Precision@{k}: {mean(precision_dict[k])}\")\n",
    "    print(f\"F1@{k}: {mean(f1_dict[k])}\")\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
