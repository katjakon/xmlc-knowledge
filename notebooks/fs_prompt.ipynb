{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retriever import Retriever\n",
    "from utils import get_label_mapping, get_title_mapping\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer,  losses, SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from utils import get_pref_label, map_labels\n",
    "import pandas as pd\n",
    "\n",
    "from gnd_dataset import GNDDataset\n",
    "from transformers import  pipeline, set_seed\n",
    "from prompt_str import SYSTEM_PROMPT, USER_PROMPT, CONTEXT_PROMPT, FS_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_model = \"BAAI/bge-m3\"\n",
    "retriever = Retriever(\n",
    "    retriever_model=retriever_model,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd_path = \"data/gnd.pickle\"\n",
    "config_path = \"configs/config_pt_baseline.yaml\"\n",
    "# Load config \n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "gnd_graph = pickle.load(open(gnd_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnd_ds = GNDDataset(\n",
    "    data_dir=config[\"dataset_path\"],\n",
    "    gnd_graph=gnd_graph,\n",
    "    config=config,\n",
    "    load_from_disk=True,\n",
    ")\n",
    "train_ds = gnd_ds[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings, mapping = get_label_mapping(graph=gnd_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 339/339 [03:22<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "index = retriever.fit(labels=strings, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = gnd_ds[\"validate\"][400]\n",
    "\n",
    "text_embeddings = retriever.retriever.encode([example[\"title\"]], show_progress_bar=False, batch_size=1024)\n",
    "similarity, indices = index.search(text_embeddings, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 47.47it/s]\n",
      "Device set to use cuda:1\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device=DEVICE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_examples = [\n",
    "    FS_PROMPT.format(\n",
    "        train_ds[int(i)][\"title\"],\n",
    "        \"; \".join(train_ds[int(i)][\"label-names\"]),\n",
    "    ) for i in indices[0]\n",
    "]\n",
    "system_prompt = f\"{SYSTEM_PROMPT} {'\\n'.join(fs_examples)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "{\"role\": \"system\", \"content\": system_prompt},\n",
    "{\"role\": \"user\", \"content\": USER_PROMPT.format(example[\"title\"])},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(messages, num_return_sequences=1, do_sample=True, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jugend; Stadt; Gewalttätigkeit; Prävention; Sozialarbeit'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][\"generated_text\"][-1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jugendgewalt im städtischen Raum Strategien und Ansätze im Umgang mit Gewalt'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"title\"]\n",
    "# 'Synökologie; Winterweizen; Aphiden; Pilze; Pflanzenschutz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jugend',\n",
       " 'Stadt',\n",
       " 'Stadtentwicklung',\n",
       " 'Öffentlicher Raum',\n",
       " 'Sozialarbeit',\n",
       " 'Prävention',\n",
       " 'Segregation (Soziologie)',\n",
       " 'Gewalttätigkeit',\n",
       " 'Sozialraumanalyse']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"label-names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv(\"results/few-shot-baseline/predictions-test-few-shot-seed-42.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_predictions = pred_df[\"raw_predictions\"].str.split(\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping predictions to GND labels: 100%|██████████| 8414/8414 [08:20<00:00, 16.81it/s]\n"
     ]
    }
   ],
   "source": [
    "mapped_predictions = map_labels(\n",
    "    prediction_list=processed_predictions,\n",
    "    index=index,\n",
    "    retriever=retriever,\n",
    "    label_mapping=mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(\n",
    "    {\n",
    "        \"predictions\": mapped_predictions,\n",
    "        \"raw_predictions\": pred_df[\"raw_predictions\"],\n",
    "        \"label-ids\": pred_df[\"label-ids\"],\n",
    "        \"label-names\": pred_df[\"label-names\"],\n",
    "        \"title\": pred_df[\"title\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>raw_predictions</th>\n",
       "      <th>label-ids</th>\n",
       "      <th>label-names</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[041665597, 04196201X, 041652436, 040118827]</td>\n",
       "      <td>Kooperativer Föderalismus; Politikverflechtung...</td>\n",
       "      <td>['040118827', '040320553', '040340139', '04130...</td>\n",
       "      <td>['Deutschland', 'Länder', 'Konferenz', 'Minist...</td>\n",
       "      <td>Die Landesministerkonferenzen und der Bund koo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[11853453X, 040192865, 041528514, 040205177, 0...</td>\n",
       "      <td>Eros; Philosophie; Platon; Foucault, Michel (1...</td>\n",
       "      <td>['041359380', '041373073', '118530941']</td>\n",
       "      <td>['Plato : Symposium', \"Foucault, Michel : L' u...</td>\n",
       "      <td>Die Geburt der Philosophie im Garten der Lüst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[042395852, 040501299, 041681843, 040213293, 0...</td>\n",
       "      <td>Glücksspiele; Risiko; Geldwäsche; Deutschland...</td>\n",
       "      <td>['040118827', '040213293', '040278336', '04076...</td>\n",
       "      <td>['Deutschland', 'Rechtsvergleich', 'Italien', ...</td>\n",
       "      <td>Das Geldwäscherisiko verschiedener Glücksspi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[947405127, 041369416, 94015739X, 040230287, 0...</td>\n",
       "      <td>CdTe; CdZnTe; Detektorsysteme; Photodetektoren...</td>\n",
       "      <td>['04124298X', '041471172', '041690257', '04171...</td>\n",
       "      <td>['Masse (Physik)', 'Teilchendetektor', 'Cadmiu...</td>\n",
       "      <td>Entwicklung von großvolumigen CdTe- und (Cd,Zn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[960068600, 97269093X, 1021247227, 041479289]</td>\n",
       "      <td>Bioinformatik; Hochdurchsatz-Analyse; Life Sci...</td>\n",
       "      <td>['042002303', '042900913', '956645356', '96006...</td>\n",
       "      <td>['Bioinformatik', 'Genanalyse', 'Open Source',...</td>\n",
       "      <td>Integrierte bioinformatische Methoden zur repr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8409</th>\n",
       "      <td>[998819808]</td>\n",
       "      <td>Humanistische Therapie, Psychotherapie, Grundl...</td>\n",
       "      <td>['998819808']</td>\n",
       "      <td>['Humanistische Therapie']</td>\n",
       "      <td>Humanistische Psychotherapie Grundlagen - Rich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8410</th>\n",
       "      <td>[04012259X, 040759962, 041738659]</td>\n",
       "      <td>Persönlichkeitspsychologie; Differentielle Psy...</td>\n",
       "      <td>['04012259X', '041550463']</td>\n",
       "      <td>['Forschungsmethode', 'Differentielle Psycholo...</td>\n",
       "      <td>Differentielle Psychologie und Persönlichkeit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8411</th>\n",
       "      <td>[1027903738]</td>\n",
       "      <td>Raspberry Pi, Linux, Smarthome, Entertainment,...</td>\n",
       "      <td>['040763706', '04160072X', '1027903738', '9409...</td>\n",
       "      <td>['Programmierung', 'Python (Programmiersprache...</td>\n",
       "      <td>Raspberry Pi – dein Einstieg Der vielseitige L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8412</th>\n",
       "      <td>[041143337, 040021742, 041235924]</td>\n",
       "      <td>Kunst; Betrachtung; Kunstwerke</td>\n",
       "      <td>['041253213']</td>\n",
       "      <td>['Kunstbetrachtung']</td>\n",
       "      <td>Neue Sicht auf Kunst Ein Beitrag zur Betrachtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>[040469484, 040538818, 040317900, 970112041, 0...</td>\n",
       "      <td>Schweiz; Reformierte Kirche; Kolonisten; Golme...</td>\n",
       "      <td>['040062872', '040139603', '040538869', '04128...</td>\n",
       "      <td>['Einwanderung', 'Bevölkerung', 'Schweizer', '...</td>\n",
       "      <td>Die Schweizer Kolonisten im Golmer Bruch bei P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8414 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            predictions  \\\n",
       "0          [041665597, 04196201X, 041652436, 040118827]   \n",
       "1     [11853453X, 040192865, 041528514, 040205177, 0...   \n",
       "2     [042395852, 040501299, 041681843, 040213293, 0...   \n",
       "3     [947405127, 041369416, 94015739X, 040230287, 0...   \n",
       "4         [960068600, 97269093X, 1021247227, 041479289]   \n",
       "...                                                 ...   \n",
       "8409                                        [998819808]   \n",
       "8410                  [04012259X, 040759962, 041738659]   \n",
       "8411                                       [1027903738]   \n",
       "8412                  [041143337, 040021742, 041235924]   \n",
       "8413  [040469484, 040538818, 040317900, 970112041, 0...   \n",
       "\n",
       "                                        raw_predictions  \\\n",
       "0     Kooperativer Föderalismus; Politikverflechtung...   \n",
       "1     Eros; Philosophie; Platon; Foucault, Michel (1...   \n",
       "2     Glücksspiele; Risiko; Geldwäsche; Deutschland...   \n",
       "3     CdTe; CdZnTe; Detektorsysteme; Photodetektoren...   \n",
       "4     Bioinformatik; Hochdurchsatz-Analyse; Life Sci...   \n",
       "...                                                 ...   \n",
       "8409  Humanistische Therapie, Psychotherapie, Grundl...   \n",
       "8410  Persönlichkeitspsychologie; Differentielle Psy...   \n",
       "8411  Raspberry Pi, Linux, Smarthome, Entertainment,...   \n",
       "8412                     Kunst; Betrachtung; Kunstwerke   \n",
       "8413  Schweiz; Reformierte Kirche; Kolonisten; Golme...   \n",
       "\n",
       "                                              label-ids  \\\n",
       "0     ['040118827', '040320553', '040340139', '04130...   \n",
       "1               ['041359380', '041373073', '118530941']   \n",
       "2     ['040118827', '040213293', '040278336', '04076...   \n",
       "3     ['04124298X', '041471172', '041690257', '04171...   \n",
       "4     ['042002303', '042900913', '956645356', '96006...   \n",
       "...                                                 ...   \n",
       "8409                                      ['998819808']   \n",
       "8410                         ['04012259X', '041550463']   \n",
       "8411  ['040763706', '04160072X', '1027903738', '9409...   \n",
       "8412                                      ['041253213']   \n",
       "8413  ['040062872', '040139603', '040538869', '04128...   \n",
       "\n",
       "                                            label-names  \\\n",
       "0     ['Deutschland', 'Länder', 'Konferenz', 'Minist...   \n",
       "1     ['Plato : Symposium', \"Foucault, Michel : L' u...   \n",
       "2     ['Deutschland', 'Rechtsvergleich', 'Italien', ...   \n",
       "3     ['Masse (Physik)', 'Teilchendetektor', 'Cadmiu...   \n",
       "4     ['Bioinformatik', 'Genanalyse', 'Open Source',...   \n",
       "...                                                 ...   \n",
       "8409                         ['Humanistische Therapie']   \n",
       "8410  ['Forschungsmethode', 'Differentielle Psycholo...   \n",
       "8411  ['Programmierung', 'Python (Programmiersprache...   \n",
       "8412                               ['Kunstbetrachtung']   \n",
       "8413  ['Einwanderung', 'Bevölkerung', 'Schweizer', '...   \n",
       "\n",
       "                                                  title  \n",
       "0     Die Landesministerkonferenzen und der Bund koo...  \n",
       "1     Die Geburt der Philosophie im Garten der Lüst...  \n",
       "2     Das Geldwäscherisiko verschiedener Glücksspi...  \n",
       "3     Entwicklung von großvolumigen CdTe- und (Cd,Zn...  \n",
       "4     Integrierte bioinformatische Methoden zur repr...  \n",
       "...                                                 ...  \n",
       "8409  Humanistische Psychotherapie Grundlagen - Rich...  \n",
       "8410  Differentielle Psychologie und Persönlichkeit...  \n",
       "8411  Raspberry Pi – dein Einstieg Der vielseitige L...  \n",
       "8412  Neue Sicht auf Kunst Ein Beitrag zur Betrachtu...  \n",
       "8413  Die Schweizer Kolonisten im Golmer Bruch bei P...  \n",
       "\n",
       "[8414 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(os.path.join(\"results/few-shot-baseline/predictions-test-few-shot-seed-42.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEW SHOT PROMPTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_negative_keywords(title, n=5):\n",
    "    text_embeddings = retriever.retriever.encode([title], show_progress_bar=False)\n",
    "    _, indices = index.search(text_embeddings, n)\n",
    "    label_list = [mapping[i] for i in indices[0]]\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = gnd_ds[\"train\"].select(range(10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:05<00:00, 1819.55it/s]\n"
     ]
    }
   ],
   "source": [
    "retriever_dict = {\n",
    "    \"anchor\": [],\n",
    "    \"positive\": [],\n",
    "}\n",
    "for i in tqdm(train_ds):\n",
    "    gold_labels_ids = i[\"label-ids\"]\n",
    "    gold_labels = i[\"label-names\"]\n",
    "    title = i[\"title\"]\n",
    "    for keyword in gold_labels:\n",
    "        retriever_dict[\"anchor\"].append(title)\n",
    "        retriever_dict[\"positive\"].append(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2161.36it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_ds = gnd_ds[\"validate\"].select(range(1000))\n",
    "eval_dict = {\n",
    "    \"anchor\": [],\n",
    "    \"positive\": [],\n",
    "}\n",
    "for i in tqdm(eval_ds):\n",
    "    gold_labels_ids = i[\"label-ids\"]\n",
    "    gold_labels = i[\"label-names\"]\n",
    "    title = i[\"title\"]\n",
    "    for keyword in gold_labels:\n",
    "        eval_dict[\"anchor\"].append(title)\n",
    "        eval_dict[\"positive\"].append(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(retriever_dict)\n",
    "eval_dataset = Dataset.from_dict(eval_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n"
     ]
    }
   ],
   "source": [
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"retriever/testing\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=1e-5,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    # Optional tracking/debugging parameters:\n",
    "    save_total_limit=2,\n",
    "    logging_steps=50,\n",
    "    run_name=\"testing\",  # Will be used in W&B if `wandb` is installed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='453' max='1290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 453/1290 08:42 < 16:10, 0.86 it/s, Epoch 1.05/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.749600</td>\n",
       "      <td>1.639668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.549800</td>\n",
       "      <td>1.528611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.447400</td>\n",
       "      <td>1.491853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.439200</td>\n",
       "      <td>1.473561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.408700</td>\n",
       "      <td>1.450809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.421800</td>\n",
       "      <td>1.425395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.375400</td>\n",
       "      <td>1.417233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.324300</td>\n",
       "      <td>1.402283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.258500</td>\n",
       "      <td>1.401772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[233]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m loss = losses.MultipleNegativesRankingLoss(model)\n\u001b[32m      3\u001b[39m trainer = SentenceTransformerTrainer(\n\u001b[32m      4\u001b[39m     model=model,\n\u001b[32m      5\u001b[39m     args=args,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     loss=loss,\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/xmlc-knowledge/ki-env/lib/python3.12/site-packages/transformers/trainer.py:2207\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2205\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2208\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/xmlc-knowledge/ki-env/lib/python3.12/site-packages/transformers/trainer.py:2549\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2542\u001b[39m context = (\n\u001b[32m   2543\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2544\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2546\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2547\u001b[39m )\n\u001b[32m   2548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2549\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2552\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2553\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2554\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2555\u001b[39m ):\n\u001b[32m   2556\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2557\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/xmlc-knowledge/ki-env/lib/python3.12/site-packages/transformers/trainer.py:3798\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3795\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   3796\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3798\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3800\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/xmlc-knowledge/ki-env/lib/python3.12/site-packages/accelerate/accelerator.py:2553\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2551\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2553\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/xmlc-knowledge/ki-env/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/xmlc-knowledge/ki-env/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/xmlc-knowledge/ki-env/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    eval_dataset=eval_dataset,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=loss,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 339/339 [03:26<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "strings, mapping = get_label_mapping(gnd_graph)\n",
    "index_fs = faiss.IndexHNSWFlat(model.get_sentence_embedding_dimension(), 200)\n",
    "label_embeddings = model.encode(strings, show_progress_bar=True, batch_size=1024)\n",
    "index_fs.add(label_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Die Bibel als Grundlage der politischen Theorie des Johannes Althusius',\n",
       " ['Althusius, Johannes : Politica methodice digesta et exemplis sacris et profanis illustrata',\n",
       "  'Althusius, Johannes (1563-1638)',\n",
       "  'Politische Theologie'],\n",
       " ['Staat',\n",
       "  'Theologie',\n",
       "  'Bibel',\n",
       "  'Politische Theorie',\n",
       "  'Kirche',\n",
       "  'Calvinismus',\n",
       "  'Althusius, Johannes : Politica methodice digesta et exemplis sacris et profanis illustrata'])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = gnd_ds[\"validate\"][2100]\n",
    "enc_example = model.encode([example[\"title\"]], show_progress_bar=False, batch_size=1024)\n",
    "ee = retriever.retriever.encode([example[\"title\"]], show_progress_bar=False, batch_size=1024)\n",
    "dist, labels =index_fs.search(enc_example, 3)\n",
    "d, ls = index.search(ee, 3)\n",
    "example[\"title\"], [get_pref_label(gnd_graph, mapping[i]) for i in labels[0]],example[\"label-names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Muscheln in meiner Hand und andere Geschichten',\n",
       " ['Alltagsgeschichte (Fach)', 'Kurzgeschichte', 'Erzählerkommentar'])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ki-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
